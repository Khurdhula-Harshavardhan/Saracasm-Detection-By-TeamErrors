{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470cbde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb40d4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c607af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b4735180",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_dataset_punctuation_cases = pd.read_csv('/Users/suchirnaik/Downloads/Saracasm-Detection-By-TeamErrors-branch_s_pre/whole_dataset_punctuation_cases.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a84d8410",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_dataset_punctuation_cases = whole_dataset_punctuation_cases[['comment','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "759e691d",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_dataset_punctuation_cases.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "721d3a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assume your dataframe is named `df` and your target variable is in a column named `target`\n",
    "X = whole_dataset_punctuation_cases.drop(columns=['label'])  # features\n",
    "y = whole_dataset_punctuation_cases['label']  # target variable\n",
    "\n",
    "# Split the data into training and testing sets with a 70/30 ratio\n",
    "X_train_whole_dataset_punctuation_cases, X_test_whole_dataset_punctuation_cases, y_train_whole_dataset_punctuation_cases, y_test_whole_dataset_punctuation_cases = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1120a95c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>199913</th>\n",
       "      <td>Let's see you shit posters get a life.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73486</th>\n",
       "      <td>yea i'm sure losing tom and bill won't hurt th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321414</th>\n",
       "      <td>Who says that the art of conversation has been...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760353</th>\n",
       "      <td>Roys our Boy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951969</th>\n",
       "      <td>I thought it was a weed snail from the thumbna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259309</th>\n",
       "      <td>Thinking that we need to listen to other peopl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366025</th>\n",
       "      <td>It'll just cauterize the butter.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131998</th>\n",
       "      <td>In other news, the Sun rose in the east today.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671562</th>\n",
       "      <td>and naturally black pete.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122021</th>\n",
       "      <td>Het is gewoon de waarheid hoor, het staat toch...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>707170 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  comment\n",
       "199913             Let's see you shit posters get a life.\n",
       "73486   yea i'm sure losing tom and bill won't hurt th...\n",
       "321414  Who says that the art of conversation has been...\n",
       "760353                                       Roys our Boy\n",
       "951969  I thought it was a weed snail from the thumbna...\n",
       "...                                                   ...\n",
       "259309  Thinking that we need to listen to other peopl...\n",
       "366025                   It'll just cauterize the butter.\n",
       "131998     In other news, the Sun rose in the east today.\n",
       "671562                          and naturally black pete.\n",
       "122021  Het is gewoon de waarheid hoor, het staat toch...\n",
       "\n",
       "[707170 rows x 1 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_whole_dataset_punctuation_cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479c8ecc",
   "metadata": {},
   "source": [
    "# Testing on the whole dataset (wcwp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8975d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f22169f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "89335e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_text = X_train_whole_dataset_punctuation_cases['comment'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "45168b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c1c9b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 65476)\t0.37940531775702935\n",
      "  (0, 45239)\t0.27389837337629414\n",
      "  (0, 88441)\t0.6335918462803942\n",
      "  (0, 102858)\t0.3452971998935748\n",
      "  (0, 129213)\t0.17471163501506587\n",
      "  (0, 101011)\t0.31517169671314826\n",
      "  (0, 65035)\t0.3612549628357834\n",
      "  (1, 3084)\t0.19472435554868395\n",
      "  (1, 6730)\t0.20705571323689598\n",
      "  (1, 114471)\t0.22916407908498337\n",
      "  (1, 53697)\t0.37186794081826136\n",
      "  (1, 127164)\t0.29666919652958684\n",
      "  (1, 11498)\t0.37989738962863684\n",
      "  (1, 4112)\t0.14017341284410173\n",
      "  (1, 116102)\t0.4139550802716116\n",
      "  (1, 66979)\t0.39050610848527567\n",
      "  (1, 111204)\t0.23932354033871434\n",
      "  (1, 128709)\t0.30869986350669965\n",
      "  (2, 66984)\t0.3938072980941733\n",
      "  (2, 10190)\t0.29533000136282883\n",
      "  (2, 50013)\t0.26438497463245725\n",
      "  (2, 23357)\t0.4689301381676785\n",
      "  (2, 80382)\t0.16805630484655243\n",
      "  (2, 6012)\t0.4374015999577879\n",
      "  (2, 114348)\t0.122861948790407\n",
      "  :\t:\n",
      "  (707166, 114348)\t0.12626550981230836\n",
      "  (707167, 97589)\t0.453953003133804\n",
      "  (707167, 110717)\t0.419375584902477\n",
      "  (707167, 33698)\t0.39529633595147473\n",
      "  (707167, 115942)\t0.3523561812402132\n",
      "  (707167, 82145)\t0.26645192852924576\n",
      "  (707167, 77670)\t0.34078587436248825\n",
      "  (707167, 55390)\t0.32002097166509014\n",
      "  (707167, 114348)\t0.21929809249336946\n",
      "  (707168, 76641)\t0.602433955403611\n",
      "  (707168, 85619)\t0.6655720570506095\n",
      "  (707168, 11954)\t0.39842623461913806\n",
      "  (707168, 4112)\t0.18799920695948696\n",
      "  (707169, 124157)\t0.36907761353132734\n",
      "  (707169, 108303)\t0.3396440540073365\n",
      "  (707169, 52728)\t0.32340471785751257\n",
      "  (707169, 115931)\t0.29317135026938757\n",
      "  (707169, 45321)\t0.3102104944833457\n",
      "  (707169, 51320)\t0.5120606667099658\n",
      "  (707169, 77982)\t0.2689395372276948\n",
      "  (707169, 38107)\t0.2081909344874965\n",
      "  (707169, 27212)\t0.20958081575474935\n",
      "  (707169, 81408)\t0.1640856426593878\n",
      "  (707169, 57636)\t0.07932971605392042\n",
      "  (707169, 80382)\t0.081446560035169\n"
     ]
    }
   ],
   "source": [
    "print(X_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3549f83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(707170, 130423)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_tfidf.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dbd1e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "662dae60",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_text = X_test_whole_dataset_punctuation_cases['comment'].tolist()\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77a1fa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "972ead33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suchirnaik/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train_tfidf, y_train_whole_dataset_punctuation_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3e7d51da",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr_model.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2b0bf9b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "13f6f9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_df = pd.DataFrame(y_pred, columns=['predicted_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c075535f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.73      0.70    151360\n",
      "           1       0.71      0.65      0.68    151713\n",
      "\n",
      "    accuracy                           0.69    303073\n",
      "   macro avg       0.69      0.69      0.69    303073\n",
      "weighted avg       0.69      0.69      0.69    303073\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_whole_dataset_punctuation_cases, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5065ca9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>373514</th>\n",
       "      <td>I liked the others, Black Flag just stood out ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582356</th>\n",
       "      <td>ayy?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683809</th>\n",
       "      <td>They want to make sure you don't miss a second...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715368</th>\n",
       "      <td>Dare I say it might have something to do with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11905</th>\n",
       "      <td>The high level artifacts from skeleton keys ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605424</th>\n",
       "      <td>Great, now we're spreading autism to Africa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645782</th>\n",
       "      <td>It's that type of elitism that causes business...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252273</th>\n",
       "      <td>FYI: Skillups for Stella and Isabelle.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107787</th>\n",
       "      <td>This is probably my second favorite comment here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495377</th>\n",
       "      <td>Seriously, the Mission was so much better when...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303073 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  comment\n",
       "373514  I liked the others, Black Flag just stood out ...\n",
       "582356                                               ayy?\n",
       "683809  They want to make sure you don't miss a second...\n",
       "715368  Dare I say it might have something to do with ...\n",
       "11905   The high level artifacts from skeleton keys ar...\n",
       "...                                                   ...\n",
       "605424     Great, now we're spreading autism to Africa...\n",
       "645782  It's that type of elitism that causes business...\n",
       "252273             FYI: Skillups for Stella and Isabelle.\n",
       "107787  This is probably my second favorite comment here.\n",
       "495377  Seriously, the Mission was so much better when...\n",
       "\n",
       "[303073 rows x 1 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_whole_dataset_punctuation_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "43c7871d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.concat([X_test_whole_dataset_punctuation_cases.reset_index(drop=True), y_test_whole_dataset_punctuation_cases.reset_index(drop=True), y_pred_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "62730be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I liked the others, Black Flag just stood out ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ayy?</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They want to make sure you don't miss a second...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dare I say it might have something to do with ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The high level artifacts from skeleton keys ar...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303068</th>\n",
       "      <td>Great, now we're spreading autism to Africa...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303069</th>\n",
       "      <td>It's that type of elitism that causes business...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303070</th>\n",
       "      <td>FYI: Skillups for Stella and Isabelle.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303071</th>\n",
       "      <td>This is probably my second favorite comment here.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303072</th>\n",
       "      <td>Seriously, the Mission was so much better when...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303073 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  comment  label  \\\n",
       "0       I liked the others, Black Flag just stood out ...      0   \n",
       "1                                                    ayy?      0   \n",
       "2       They want to make sure you don't miss a second...      0   \n",
       "3       Dare I say it might have something to do with ...      0   \n",
       "4       The high level artifacts from skeleton keys ar...      0   \n",
       "...                                                   ...    ...   \n",
       "303068     Great, now we're spreading autism to Africa...      1   \n",
       "303069  It's that type of elitism that causes business...      0   \n",
       "303070             FYI: Skillups for Stella and Isabelle.      0   \n",
       "303071  This is probably my second favorite comment here.      0   \n",
       "303072  Seriously, the Mission was so much better when...      1   \n",
       "\n",
       "        predicted_label  \n",
       "0                     1  \n",
       "1                     0  \n",
       "2                     1  \n",
       "3                     1  \n",
       "4                     0  \n",
       "...                 ...  \n",
       "303068                1  \n",
       "303069                0  \n",
       "303070                0  \n",
       "303071                0  \n",
       "303072                1  \n",
       "\n",
       "[303073 rows x 3 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e1d7aa57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sarcastic Accuracy: 0.6914670722895144\n"
     ]
    }
   ],
   "source": [
    "accuracy = (result_df[\"label\"] == result_df[\"predicted_label\"]).mean()\n",
    "print(\"Sarcastic Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0da3fc8",
   "metadata": {},
   "source": [
    "# Testing on sarcastic data only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6fdf129e",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_train_dataset = pd.concat([X_test_whole_dataset_punctuation_cases.reset_index(drop=True), y_test_whole_dataset_punctuation_cases.reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f6030466",
   "metadata": {},
   "outputs": [],
   "source": [
    "sarcastic_dataset_punctuation_cases = whole_train_dataset[whole_train_dataset['label']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b0452d3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[Because he's only half a Norse god, while his...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Since he has feats for catching the ultimate A...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>No, nobody does.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Any support VSAA VSAA VRS VRS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Was EU a typo too?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303061</th>\n",
       "      <td>Don't worry, Trump will bring back all the coa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303064</th>\n",
       "      <td>No, that was Bushs' fault.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303066</th>\n",
       "      <td>Why don't you just get a better job?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303068</th>\n",
       "      <td>Great, now we're spreading autism to Africa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303072</th>\n",
       "      <td>Seriously, the Mission was so much better when...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151713 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  comment  label\n",
       "5       [Because he's only half a Norse god, while his...      1\n",
       "6       Since he has feats for catching the ultimate A...      1\n",
       "7                                        No, nobody does.      1\n",
       "8                           Any support VSAA VSAA VRS VRS      1\n",
       "9                                      Was EU a typo too?      1\n",
       "...                                                   ...    ...\n",
       "303061  Don't worry, Trump will bring back all the coa...      1\n",
       "303064                         No, that was Bushs' fault.      1\n",
       "303066               Why don't you just get a better job?      1\n",
       "303068     Great, now we're spreading autism to Africa...      1\n",
       "303072  Seriously, the Mission was so much better when...      1\n",
       "\n",
       "[151713 rows x 2 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sarcastic_dataset_punctuation_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7134c3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sarcastic_dataset_punctuation_cases= sarcastic_dataset_punctuation_cases[['comment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cf3ffff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_sarcastic_dataset_punctuation_cases = sarcastic_dataset_punctuation_cases[['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "89a4b802",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suchirnaik/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/0w/78_w9pm16ts4trsks5rjpd440000gn/T/ipykernel_5994/4101299108.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX_train_tfidf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfidf_vectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlr_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mlr_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_tfidf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train_sarcastic_dataset_punctuation_cases\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_tfidf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_classes\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1554\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   1555\u001b[0m                 \u001b[0;34m\"This solver needs samples of at least 2 classes\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1556\u001b[0m                 \u001b[0;34m\" in the data, but the data contains only one\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 1"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_text = X_train_sarcastic_dataset_punctuation_cases['comment'].tolist()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train_text)\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train_tfidf, Y_train_sarcastic_dataset_punctuation_cases)\n",
    "y_pred = lr_model.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6fc89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#not possible to test only data with only one class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80aa7b3c",
   "metadata": {},
   "source": [
    "# NCNP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b273a517",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "739065e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Remove unnecessary characters(special characters) and convert to lowercase\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text).lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cd52ee11",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'whole_dataset_npnc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/0w/78_w9pm16ts4trsks5rjpd440000gn/T/ipykernel_5994/2363311947.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwhole_dataset_npnc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'whole_dataset_npnc' is not defined"
     ]
    }
   ],
   "source": [
    "whole_dataset_npnc.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f0fa6278",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_dataset_punctuation_cases['processed_comment'] = whole_dataset_punctuation_cases['comment'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3f0ac2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_dataset_npnc = whole_dataset_punctuation_cases[['processed_comment','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0374e8e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>processed_comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nc and nh</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>you do know west teams play against west teams...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>they were underdogs earlier today  but since g...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this meme isn t funny none of the  new york ni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i could use one of those tools</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010768</th>\n",
       "      <td>i m sure that iran and n  korea have the techn...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010769</th>\n",
       "      <td>whatever you do  don t vote green</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010770</th>\n",
       "      <td>perhaps this is an atheist conspiracy to make ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010771</th>\n",
       "      <td>the slavs got their own country   it is called...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010772</th>\n",
       "      <td>values  as in capitalism    there is good mone...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1010243 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         processed_comment  label\n",
       "0                                               nc and nh       0\n",
       "1        you do know west teams play against west teams...      0\n",
       "2        they were underdogs earlier today  but since g...      0\n",
       "3        this meme isn t funny none of the  new york ni...      0\n",
       "4                          i could use one of those tools       0\n",
       "...                                                    ...    ...\n",
       "1010768  i m sure that iran and n  korea have the techn...      1\n",
       "1010769                 whatever you do  don t vote green       1\n",
       "1010770  perhaps this is an atheist conspiracy to make ...      1\n",
       "1010771  the slavs got their own country   it is called...      1\n",
       "1010772  values  as in capitalism    there is good mone...      1\n",
       "\n",
       "[1010243 rows x 2 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole_dataset_npnc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "db5b2dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assume your dataframe is named `df` and your target variable is in a column named `target`\n",
    "X = whole_dataset_npnc.drop(columns=['label'])  # features\n",
    "y = whole_dataset_npnc['label']  # target variable\n",
    "\n",
    "# Split the data into training and testing sets with a 70/30 ratio\n",
    "X_train_whole_dataset_npnc, X_test_whole_dataset_npnc, y_train_whole_dataset_npnc, y_test_whole_dataset_npnc = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6190cb18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suchirnaik/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_text = X_train_whole_dataset_npnc['processed_comment'].tolist()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train_text)\n",
    "X_test_text = X_test_whole_dataset_npnc['processed_comment'].tolist()\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test_text)\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train_tfidf, y_train_whole_dataset_npnc)\n",
    "y_pred = lr_model.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a338e398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.73      0.70    151360\n",
      "           1       0.71      0.65      0.68    151713\n",
      "\n",
      "    accuracy                           0.69    303073\n",
      "   macro avg       0.69      0.69      0.69    303073\n",
      "weighted avg       0.69      0.69      0.69    303073\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_whole_dataset_punctuation_cases, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147d805d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26d9803",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9260c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
